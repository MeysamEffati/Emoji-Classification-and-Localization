# -*- coding: utf-8 -*-
"""Copy of Image Detection and Localization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EdAhUHS8M4yYjd9nrj7tJCb_kB0olgBS
"""

import matplotlib.pyplot as plt
import tensorflow as tf
import os
import numpy as np

from tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, Dropout, MaxPooling1D

"""**`Downloading the Dataset `**"""

!wget https://github.com/hfg-gmuend/openmoji/releases/latest/download/openmoji-72x72-color.zip

!mkdir EmojiDetection

!unzip -q openmoji-72x72-color.zip -d ./EmojiDetection

"""Creating 9 classes of the emojies"""

emojifiles ={
    0: {'name': 'happy', 'file': '1F642.png'},
    1: {'name': 'laughing', 'file': '1F602.png'},
    2: {'name': 'skeptical', 'file': '1F928.png'},
    3: {'name': 'sad', 'file': '1F630.png'},
    4: {'name': 'cool', 'file': '1F60E.png'},
    5: {'name': 'whoa', 'file': '1F62F.png'},
    6: {'name': 'crying', 'file': '1F62D.png'},
    7: {'name': 'puking', 'file': '1F92E.png'},
    8: {'name': 'nervous', 'file': '1F62C.png'}
}

for x, (y,z) in enumerate(emojifiles.items()):
  plt.subplot(3,3, x+1)
  path = os.path.join("EmojiDetection", z['file'])
  plt.imshow(plt.imread(path))
  plt.title(z['name'])
  plt.xticks([])
  plt.yticks([])
plt.show()

"""Adding the 9 emojies to the class of 9 classes

"""

from PIL import Image, ImageDraw

for x, (y,z) in enumerate(emojifiles.items()):
  imageopen = Image.open(os.path.join("EmojiDetection", z['file'])).convert("RGBA")
  imageopen.load()
  imagenew = Image.new("RGB",imageopen.size, (255, 255, 255))
  imagenew.paste(imageopen, mask=imageopen.split()[3])
  emojifiles[x]['image'] = imagenew
imagenew.split()

emojifiles

"""Creating new images using the original emgies by chaning the size as well as the moving the emjoes on the new images"""

def create_image(emojifiles):
  randnum_class = np.random.randint(0,9)
  newimage = np.ones([144, 144, 3])*250
  col = np.random.randint(0,72)
  row = np.random.randint(0,72)
  newimage[row:row + 72,col: col + 72,:] = emojifiles[randnum_class]['image']
  classID = randnum_class
  return newimage.astype('uint8'), row , col, classID

newimage, row , col, classID = create_image(emojifiles)
plt.imshow(newimage)

def plot_BoundingBox(emojifiles, predicted):
  newimage, row , col, classID = create_image(emojifiles)
  newimage = Image.fromarray(newimage)
  draw = ImageDraw.Draw(newimage)
  draw.rectangle((col + 10, row + 10, col + 72 - 10, row + 72 - 10), outline = 'green')


  if predicted:
    draw.rectangle((col + 10, row + 10, col + 72 - 10, row + 72 - 10), outline = 'red')
  return newimage

newimage = plot_BoundingBox(emojifiles, True)
plt.imshow(newimage)

batchsize = 10
def DataGenerator(batchsize = 500):
  while True:
    x_batch = np.zeros((batchsize, 144, 144, 3))
    y_batch = np.zeros((batchsize, 9))
    bbx_batch = np.zeros((batchsize, 2))
    for i in range(batchsize):
      newimage, row , col, classID = create_image(emojifiles)
      x_batch[i] = newimage
      y_batch[i, classID] = 1.0
      bbx_batch[i] = [row, col]
    yield {"image":x_batch}, {"ClassID": y_batch, "bbx_out":bbx_batch}

"""Creating the Model"""

from tensorflow.keras.layers import Conv2D, Dense, Dropout, BatchNormalization, MaxPool2D, Input, Flatten
from tensorflow.keras.models import Model

input_ = Input(shape=(144, 144, 3), name = 'image')
x = input_
for i in range(0, 5):
  n_filters = 2**(4+i)
  x = Conv2D(n_filters, 3, activation = 'relu')(x)
  x = BatchNormalization()(x)
  x = MaxPool2D(2)(x)
x = Flatten()(x)
x = Dense(256, activation = 'relu')(x)
y_batch = Dense(9, activation='softmax', name='y_batch')(x)
bbx_out=Dense(2, name='bbx_out')(x)
model = tf.keras.models.Model(input_, [y_batch, bbx_out])
model.summary()

"""Intersection over Union (IoU)



"""

@tf.keras.saving.register_keras_serializable()

class IoU(tf.keras.metrics.Metric):
  def __init__(self, **kwargs):
    super(IoU, self).__init__(**kwargs)
    self.iou = self.add_weight(name = 'iou', initializer='zeros')
    self.total_iou = self.add_weight(name = 'total_iou', initializer = 'zeros')
    self.num_ex = self.add_weight(name='num_ex', initializer='zeros')
  def update_state(self, y_true, y_pred, sample_weight=None):
    def get_box(y):
      rows, cols = y[:, 0], y[:, 1]
      rows, cols = rows*144, cols*144
      y1, y2 = rows, rows + 52
      x1, x2 = cols, cols + 52
      return x1, y1, x2, y2

    def get_area(x1, y1, x2, y2):
      return tf.math.abs(x2 - x1) * tf.math.abs(y2 - y1)

    gt_x1, gt_y1, gt_x2, gt_y2 = get_box(y_true)
    p_x1, p_y1, p_x2, p_y2 = get_box(y_pred)
    i_x1 = tf.maximum(gt_x1, p_x1)
    i_y1 = tf.maximum(gt_y1, p_y1)
    i_x2 = tf.minimum(gt_x2, p_x2)
    i_y2 = tf.minimum(gt_y2, p_y2)

    i_area = get_area(i_x1, i_y1, i_x2, i_y2)
    u_area = get_area(gt_x1, gt_y1, gt_x2, gt_y2) + get_area(p_x1, p_y1, p_x2, p_y2) - i_area
    iou = tf.math.divide(i_area, u_area)
    self.num_ex.assign_add(1)
    self.total_iou.assign_add(tf.reduce_mean(iou))
    self.iou = tf.math.divide(self.total_iou, self.num_ex)
  def result(self):
    return self.iou

  def reset_state(self):
    self.iou = self.add_weight(name= 'iou', initializer = 'zeros')
    self.total_iou = self.add_weight(name = 'total_iou', initializer = 'zeros')
    self.num_ex = self.add_weight(name = 'num_ex', initializer = 'zeros')

model.compile(loss = {'y_batch': 'categorical_crossentropy',
                      'bbx_out': 'mse'
                      },
              optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001),
              metrics = {
                  'y_batch': 'accuracy',

                  'bbx_out': IoU(name = 'iou')
              }
)

"""Training Process"""

Data_Gen = next(DataGenerator())
x_ = Data_Gen[0]['image']
y_ = Data_Gen[1]['ClassID']
z_ = Data_Gen[1]['bbx_out']
model.fit(x_, [y_,z_], epochs= 100 , steps_per_epoch=500)

from google.colab import drive
drive.mount('/content/drive')

model.save('/content/drive/My Drive/image_localization_Classification.keras')

model = tf.keras.models.load_model('/content/drive/My Drive/image_localization_Classification.keras')

def plot_BoundingBox(emojifiles, create_image_out_predicted, create_image_out_gt, ): #newimage, row , col, classID = create_image_out
  newimage, row , col, classID = create_image_out_gt
  newimage = Image.fromarray(newimage)
  draw = ImageDraw.Draw(newimage)
  draw.rectangle((col + 10, row + 10, col + 72 - 10, row + 72 - 10), outline = 'green')
  row , col, classID_pred = create_image_out_predicted
  draw.rectangle((col + 10, row + 10, col + 72 - 10, row + 72 - 10), outline = 'red')
  Predicted_Label = emojifiles[classID_pred]['name']
  Groundtruth_Label = emojifiles[np.argmax(classID)]['name']
  color = 'green' if classID_pred == np.argmax(classID) else 'red'
  plt.xlabel(f'pred: {Predicted_Label}', color = color)
  plt.ylabel(f'gt: {Groundtruth_Label}', color = color)

  return newimage

out_datagen = next(DataGenerator(3))
out_datagen_image = out_datagen[0]['image']
out_datagen_ClassID = out_datagen[1]['ClassID']
out_datagen_bbx_out = out_datagen[1]['bbx_out']
prediction_result = model.predict(out_datagen_image)
prediction_result_classID = np.argmax(prediction_result[0])
prediction_result_box = prediction_result[1]
print("out_datagen_bbx_out:", out_datagen_bbx_out, "prediction_result_box:", prediction_result_box )

predicted = False
create_image_out_gt = out_datagen_image[0].astype('uint8'), out_datagen_bbx_out[0][0] , out_datagen_bbx_out[0][1], out_datagen_ClassID
create_image_out_predicted = prediction_result_box[0][0] , prediction_result_box[0][1], prediction_result_classID
predict = True
image_predicted = plot_BoundingBox(emojifiles, create_image_out_predicted, create_image_out_gt) #newimage, row , col, classID = create_image_out
plt.imshow(image_predicted)
plt.show()